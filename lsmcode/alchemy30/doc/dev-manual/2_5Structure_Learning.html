<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.70)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>2.5 Structure Learning</TITLE>
<META NAME="description" CONTENT="2.5 Structure Learning">
<META NAME="keywords" CONTENT="manual">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="manual.css">

<LINK REL="next" HREF="2_6Inference.html">
<LINK REL="previous" HREF="2_4Weight_Learning.html">
<LINK REL="up" HREF="2Notes_on_Code_Design.html">
<LINK REL="next" HREF="2_6Inference.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html92"
  HREF="2_6Inference.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html90"
  HREF="2Notes_on_Code_Design.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html84"
  HREF="2_4Weight_Learning.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A>   
<BR>
<B> Next:</B> <A NAME="tex2html93"
  HREF="2_6Inference.html">2.6 Inference</A>
<B> Up:</B> <A NAME="tex2html91"
  HREF="2Notes_on_Code_Design.html">2 Notes on Code</A>
<B> Previous:</B> <A NAME="tex2html85"
  HREF="2_4Weight_Learning.html">2.4 Weight Learning</A>
<BR>
<BR>
<!--End of Navigation Panel-->

<H2><A NAME="SECTION00025000000000000000"></A>
<A NAME="learnstructdir"></A>
<BR>
2.5 Structure Learning
</H2>
The <TT>learnstruct/</TT> directory contains code for the generative learning 
of MLN structure. The mainline is in <TT>learnstruct.cpp</TT>.
Table&nbsp;<A HREF="#tab:cllearnstruct">2</A> shows the options available when calling learnstruct.

<P>
<DIV ALIGN="CENTER">
</DIV>
<P>
<DIV ALIGN="CENTER">
</DIV>
<BR><P></P>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>&lt;-i &lt;string&#187;</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>Comma-separated input .mln files. (With the -multipleDatabases option, the second file to the last one are used to contain constants from different domains, and they correspond to the .db files specified with the -t option.)</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>&lt;-o &lt;string&#187;</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>Output .mln file containing learned formulas and weights.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>&lt;-t &lt;string&#187;</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>Comma-separated .db files containing the training database (of true/false ground atoms), including function definitions, e.g. ai.db,graphics.db,languages.db.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-ne &lt;string&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[all predicates] Non-evidence predicates (comma-separated with no space), e.g., cancer,smokes,friends.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-multipleDatabases [bool]]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>If specified, each .db file belongs to a separate domain; otherwise all .db files belong to the same domain.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-beamSize &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[5] Size of beam in beam search.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-minWt &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[0.01] Candidate clauses are discarded if their absolute weights fall below this.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-penalty &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[0.01] Each difference between the current and previous version of a candidate clause penalizes the (weighted) pseudo-log-likelihood by this amount.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-maxVars &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[6] Maximum number of variables in learned clauses.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-maxNumPredicates &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[6] Maximum number of predicates in learned clauses.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-cacheSize &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[500] Size in megabytes of the cache that is used to store the clauses (and their counts) that are created during structure learning.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-noSampleClauses [bool]]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>If specified, compute a clause's number of true groundings exactly, and do not estimate it by sampling its groundings. If not specified, estimate the number by sampling.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-delta &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[0.05] (Used only if sampling clauses.) The probability that an estimate a clause's number of true groundings is off by more than epsilon error is less than this value. Used to determine the number of samples of the clause's groundings to draw.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-epsilon &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[0.2] (Used only if sampling clauses.) Fractional error from a clause's actual number of true groundings. Used to determine the number of samples of the clause's groundings to draw.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-minClauseSamples &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[-1] (Used only if sampling clauses.) Minimum number of samples of a clause's groundings to draw. (-1: no minimum)</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-maxClauseSamples &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[-1] (Used only if sampling clauses.) Maximum number of samples of a clause's groundings to draw. (-1: no maximum)</TD>
</TR>
</TABLE>

<P>

</DIV>
<BR>
<DIV ALIGN="CENTER">
</DIV>
<P>
<DIV ALIGN="CENTER">
</DIV>
<BR><P></P>
<DIV ALIGN="CENTER">
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-noSampleAtoms [bool]]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>If specified, do not estimate the (weighted) pseudo-log-likelihood by sampling ground atoms; otherwise, estimate the value by sampling.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-fractAtoms &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[0.8] (Used only if sampling ground atoms.) Fraction of each predicate's ground atoms to draw.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-minAtomSamples &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[-1] (Used only if sampling ground atoms.) Minimum number of each predicate's ground atoms to draw. (-1: no minimum)</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-maxAtomSamples &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[-1] (Used only if sampling ground atoms.) Maximum number of each predicate's ground atoms to draw. (-1: no maximum)</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-noPrior [bool]]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>No Gaussian priors on formula weights.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-priorMean &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[0] Means of Gaussian priors on formula weights. By default, for each formula, it is the weight given in the .mln input file, or fraction thereof if the formula turns into multiple clauses. This mean applies if no weight is given in the .mln file.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-priorStdDev &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[100] Standard deviations of Gaussian priors on clause weights.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-tightMaxIter &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[10000] Max number of iterations to run L-BFGS-B, the algorithm used to optimize the (weighted) pseudo-log-likelihood.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-tightConvThresh &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[1e-5] Fractional change in (weighted) pseudo-log-likelihood at which L-BFGS-B terminates.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-looseMaxIter &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[10] Max number of iterations to run L-BFGS-B when evaluating candidate clauses.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-looseConvThresh &lt;double&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[1e-3] Fractional change in (weighted) pseudo-log-likelihood at which L-BFGS-B terminates when evaluating candidate clauses.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-numClausesReEval &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[10] Keep this number of candidate clauses with the highest estimated scores, and re-evaluate their scores precisely.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-noWtPredsEqually [bool]]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>If specified, each predicate is not weighted equally. This means that high-arity predicates contribute more to the pseudo-log-likelihood than low-arity ones. If not specified, each predicate is given equal weight in the weighted pseudo-log-likelihood.</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-startFromEmptyMLN [bool]]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>If specified, start structure learning from an empty MLN. If the input .mln contains formulas, they will be added to the candidate clauses created in the first step of beam search. If not specified, begin structure learning from the input .mln file.</TD>
</TR>
</TABLE>

<P>

</DIV>
<BR>
<DIV ALIGN="CENTER">
</DIV>
<P>
<DIV ALIGN="CENTER">
</DIV>
<BR><P></P>
<DIV ALIGN="CENTER"><A NAME="271"></A>
<TABLE>
<CAPTION><STRONG>Table 2:</STRONG>
Command line options for learnstruct</CAPTION>
<TR><TD><TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-tryAllFlips [bool]]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>If specified, the structure learning algorithm tries to flip the predicate signs of the formulas in the input .mln file in all possible ways</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=156><TT>[-bestGainUnchangedLimit &lt;integer&gt;]</TT></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=298>[2] Beam search stops when the best clause found does not change in this number of iterations.</TD>
</TR>
</TABLE>

<P>

<A NAME="tab:cllearnstruct"></A></TD></TR>
</TABLE>
</DIV><P></P>
<BR>
<DIV ALIGN="CENTER">
</DIV>
<P>
<DIV ALIGN="CENTER">
</DIV>

<P>
<TT>structlearn.h</TT> contains 
most of the structure learning code. <TT>structlearn.cpp</TT> contains the 
code that handles formulas with variables that are existentially 
quantified, or have mutually exclusive and exhaustive values.

<P>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html92"
  HREF="2_6Inference.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html90"
  HREF="2Notes_on_Code_Design.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html84"
  HREF="2_4Weight_Learning.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A>   
<BR>
<B> Next:</B> <A NAME="tex2html93"
  HREF="2_6Inference.html">2.6 Inference</A>
<B> Up:</B> <A NAME="tex2html91"
  HREF="2Notes_on_Code_Design.html">2 Notes on Code</A>
<B> Previous:</B> <A NAME="tex2html85"
  HREF="2_4Weight_Learning.html">2.4 Weight Learning</A>
<!--End of Navigation Panel-->
<ADDRESS>
Marc Sumner
2007-01-16
</ADDRESS>
</BODY>
</HTML>
